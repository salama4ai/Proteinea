{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e363d37-64ad-465d-ac56-e4f08a685128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2981b9-9a12-4d28-8407-4750ea107db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version= 1.12.1+cu116,\n",
      "Cuda version=11.6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch version= {torch.__version__},\\nCuda version={torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8f11e5-80b6-4aa4-ab60-19329c4df5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>month</th>\n",
       "      <th>leap_year_condition</th>\n",
       "      <th>decade</th>\n",
       "      <th>output</th>\n",
       "      <th>output_year_digit</th>\n",
       "      <th>output_year</th>\n",
       "      <th>output_day</th>\n",
       "      <th>valid_years_days_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1800</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [1, 8, 15, 22, 29], 1: [7, 14, 21, 28], 2:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1801</td>\n",
       "      <td>1</td>\n",
       "      <td>1801</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [2, 9, 16, 23, 30], 1: [1, 8, 15, 22, 29],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1802</td>\n",
       "      <td>2</td>\n",
       "      <td>1802</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [3, 10, 17, 24, 31], 1: [2, 9, 16, 23, 30]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1803</td>\n",
       "      <td>3</td>\n",
       "      <td>1803</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [4, 11, 18, 25], 1: [3, 10, 17, 24, 31], 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1804</td>\n",
       "      <td>4</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "      <td>{4: [1, 8, 15, 22, 29], 8: [3, 10, 17, 24, 31]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday_name  month  leap_year_condition  decade    output  \\\n",
       "0             2      1                    0     180  1-1-1800   \n",
       "1             3      1                    0     180  1-1-1801   \n",
       "2             4      1                    0     180  1-1-1802   \n",
       "3             5      1                    0     180  1-1-1803   \n",
       "4             6      1                    1     180  1-1-1804   \n",
       "\n",
       "   output_year_digit  output_year  output_day  \\\n",
       "0                  0         1800           1   \n",
       "1                  1         1801           1   \n",
       "2                  2         1802           1   \n",
       "3                  3         1803           1   \n",
       "4                  4         1804           1   \n",
       "\n",
       "                                   valid_years_days_  \n",
       "0  {0: [1, 8, 15, 22, 29], 1: [7, 14, 21, 28], 2:...  \n",
       "1  {0: [2, 9, 16, 23, 30], 1: [1, 8, 15, 22, 29],...  \n",
       "2  {0: [3, 10, 17, 24, 31], 1: [2, 9, 16, 23, 30]...  \n",
       "3  {0: [4, 11, 18, 25], 1: [3, 10, 17, 24, 31], 2...  \n",
       "4    {4: [1, 8, 15, 22, 29], 8: [3, 10, 17, 24, 31]}  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819e6f7-ab45-457b-bf87-61615c359763",
   "metadata": {},
   "source": [
    "**A- training for getting the year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45df77eb-a8e1-42e9-b5ec-dd230aad80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random number generation aka regenerate the same random numbers every time (such as weight and bias initialization )\n",
    "def set_random_seed(seed=7, deterministic=True):\n",
    "    \"\"\"Set random seed, for python, numpy, pytorch\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed to be used.\n",
    "        deterministic (bool): Whether to set the deterministic option for\n",
    "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
    "            to True and `torch.backends.cudnn.benchmark` to False.\n",
    "            Default: True.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False \n",
    "seed=7        \n",
    "set_random_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556798f8-2f85-4c15-a87a-5e8eb28df59d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leap_year_condition</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   leap_year_condition  decade\n",
       "0                    0     180\n",
       "1                    0     180\n",
       "2                    0     180\n",
       "3                    0     180\n",
       "4                    1     180\n",
       "5                    0     180\n",
       "6                    0     180"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_year column is just the last number in the output column\n",
    "x_year = df[[\"leap_year_condition\", \"decade\", \"valid_years_days_\", \"output_year_digit\"]]\n",
    "y_year = x_year.pop(\"output_year_digit\")\n",
    "v = x_year.pop(\"valid_years_days_\")\n",
    "x_year.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91dd3f7b-3d89-4827-a02f-a82febf514cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "xtrain_year, xtest_year, ytrain_year, ytest_year, vtrain_year, vtest_year = train_test_split(x_year, y_year, v, test_size=0.19, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "class CollectedData(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.data = torch.tensor(x.values.astype(np.float32))\n",
    "        self.label = torch.tensor(y.values)\n",
    "        self.n_smpl = x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_smpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093c401f-dc3c-4116-bd2b-47f00a61b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_year = CollectedData(xtrain_year, ytrain_year)\n",
    "test_set_year = CollectedData(xtest_year, ytest_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f0dd21d-1a26-47f1-b539-247bd301243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this isn't suitable here, so that i used train_test_split function\n",
    "# # train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-test_len, int(len(dataset)*0.2)])\n",
    "\n",
    "# train_labels_year = torch.tensor(ytrain_year.values.astype(np.float32)) \n",
    "# test_labels_year = torch.tensor(ytest_year.values.astype(np.float32)) \n",
    "# train_input_year = torch.tensor(xtrain_year.values.astype(np.float32)) \n",
    "# test_input_year = torch.tensor(xtest_year.values.astype(np.float32)) \n",
    "\n",
    "# train_set_year = TensorDataset(train_input_year, train_labels_year)\n",
    "# test_set_year = TensorDataset(test_input_year, test_labels_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a348e6-c679-4bc9-9abe-1772254e1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_year = DataLoader(dataset=train_set_year, shuffle=True, batch_size=batch_size)\n",
    "test_loader_year = DataLoader(dataset=test_set_year, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e0e4d8c-8278-4f9c-a14a-a1b499d63b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class network(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 11)\n",
    "        self.fc2 = nn.Linear(11, 11)\n",
    "        self.fc3 = nn.Linear(11, 11)\n",
    "        self.fc4 = nn.Linear(11, out_features) \n",
    "        self.initialize_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.fc1(x))\n",
    "        out = F.leaky_relu(self.fc2(out))\n",
    "        out = F.leaky_relu(self.fc3(out))\n",
    "        out = (self.fc4(out))#nn.Softmax\n",
    "        return out\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8266a2c3-42c6-48ea-9ace-f6957f5b87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy\n",
    "@torch.no_grad()\n",
    "def calculate_accuracy(model, data_loader=train_loader_year):\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for data, labels in data_loader:\n",
    "        \n",
    "        # transfering data to cuda\n",
    "        data = data.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "                \n",
    "        preds = model(data)\n",
    "        num_correct += (preds.argmax(dim=1) == labels).sum().item()\n",
    "        num_samples += len(labels)\n",
    "    accuracy = num_correct/num_samples\n",
    "    model.train()\n",
    "    return accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0da7dd2-23a6-4b27-bba5-642421fd2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the network\n",
    "model = network(in_features=2, out_features=10).to(device)\n",
    "lr = 0.05\n",
    "# loss and optimizer initializing\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.001, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350619a6-e65d-472e-be51-d6c48ce32129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting learning rate = 0.05 \n",
      " number of epochs = 10 \n",
      " number of batches = 3708 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [1/10], loss=2.3324:  20%|█████████▉                                         | 724/3708 [00:09<00:27, 107.88it/s]"
     ]
    }
   ],
   "source": [
    "def train_model(data_loader=train_loader_year):\n",
    "    num_batches = len(data_loader)\n",
    "    num_epochs = 10\n",
    "    # starting training loop epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"starting learning rate = {lr} \\n number of epochs = {num_epochs} \\n number of batches = {num_batches} \\n\")\n",
    "        progress = tqdm(enumerate(data_loader), total=num_batches, leave=True)\n",
    "        for batch_idx, (data, labels) in progress: \n",
    "\n",
    "            # convert data to device\n",
    "            data = data.to(device=device)\n",
    "            labels = labels.to(device=device)        \n",
    "\n",
    "            # getting prediction and loss\n",
    "            preds = model(data)\n",
    "            loss = criterion(preds, labels)        \n",
    "\n",
    "            # back propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # optimization step\n",
    "            optimizer.step()\n",
    "\n",
    "            progress.set_description(f\"epoch [{1+epoch}/{num_epochs}], loss={loss.item():0.4f}\")\n",
    "            progress.set_postfix()\n",
    "\n",
    "        acc = calculate_accuracy(model, data_loader=train_loader_year)\n",
    "        schedular.step(acc)\n",
    "        print(f\"after {1+epoch} epoch, accuracy = {(acc*100):.2f}%\")\n",
    "train_model(data_loader=train_loader_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d7594-25e6-44c6-a479-8eda01194a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_day = df[[\"weekday_name\", \"month\", \"output_year\", \"output_day\"]]\n",
    "x_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d1ca6-8b0b-483a-8093-98063b5d3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_day = x_day.pop(\"output_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f07c8-6b95-4d2e-bce1-d6f79a05d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "xtrain_day, xtest_day, ytrain_day, ytest_day, vtrain_day, vtest_day = train_test_split(x_day, y_day, v, test_size=0.19, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53160ba8-d24d-49f4-afc3-13527a42febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_day = CollectedData(xtrain_day, ytrain_day)\n",
    "test_set_day = CollectedData(xtest_day, ytest_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8fadcf-5a39-4695-80cf-d84f8045c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this isn't suitable here, so that i used train_test_split function\n",
    "# # train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-test_len, int(len(dataset)*0.2)])\n",
    "\n",
    "# train_labels_year = torch.tensor(ytrain_year.values.astype(np.float32)) \n",
    "# test_labels_year = torch.tensor(ytest_year.values.astype(np.float32)) \n",
    "# train_input_year = torch.tensor(xtrain_year.values.astype(np.float32)) \n",
    "# test_input_year = torch.tensor(xtest_year.values.astype(np.float32)) \n",
    "\n",
    "# train_set_year = TensorDataset(train_input_year, train_labels_year)\n",
    "# test_set_year = TensorDataset(test_input_year, test_labels_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59967977-91aa-480e-ab09-85228beb4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_day = DataLoader(dataset=train_set_day, shuffle=True, batch_size=batch_size)\n",
    "test_loader_day = DataLoader(dataset=test_set_day, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fdfc3a-c4b8-4224-836d-b5931796b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(data_loader=test_loader_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173ae8b-8aeb-4ace-8f2f-d2a16b4575be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
