{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e363d37-64ad-465d-ac56-e4f08a685128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time    \n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2981b9-9a12-4d28-8407-4750ea107db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version= 1.12.1+cu116,\n",
      "Cuda version=11.6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch version= {torch.__version__},\\nCuda version={torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8f11e5-80b6-4aa4-ab60-19329c4df5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>month</th>\n",
       "      <th>leap_year_condition</th>\n",
       "      <th>decade</th>\n",
       "      <th>output</th>\n",
       "      <th>output_year_digit</th>\n",
       "      <th>output_year</th>\n",
       "      <th>output_day</th>\n",
       "      <th>valid_years_days_dict</th>\n",
       "      <th>valid_years_list</th>\n",
       "      <th>valid_day_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1800</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [1, 8, 15, 22, 29], 1: [7, 14, 21, 28], 2:...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1801</td>\n",
       "      <td>1</td>\n",
       "      <td>1801</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [2, 9, 16, 23, 30], 1: [1, 8, 15, 22, 29],...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1802</td>\n",
       "      <td>2</td>\n",
       "      <td>1802</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [3, 10, 17, 24, 31], 1: [2, 9, 16, 23, 30]...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1803</td>\n",
       "      <td>3</td>\n",
       "      <td>1803</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [4, 11, 18, 25], 1: [3, 10, 17, 24, 31], 2...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1804</td>\n",
       "      <td>4</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "      <td>{4: [1, 8, 15, 22, 29], 8: [3, 10, 17, 24, 31]}</td>\n",
       "      <td>[4, 8, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday_name  month  leap_year_condition  decade    output  \\\n",
       "0             2      1                    0     180  1-1-1800   \n",
       "1             3      1                    0     180  1-1-1801   \n",
       "2             4      1                    0     180  1-1-1802   \n",
       "3             5      1                    0     180  1-1-1803   \n",
       "4             6      1                    1     180  1-1-1804   \n",
       "\n",
       "   output_year_digit  output_year  output_day  \\\n",
       "0                  0         1800           1   \n",
       "1                  1         1801           1   \n",
       "2                  2         1802           1   \n",
       "3                  3         1803           1   \n",
       "4                  4         1804           1   \n",
       "\n",
       "                               valid_years_days_dict  \\\n",
       "0  {0: [1, 8, 15, 22, 29], 1: [7, 14, 21, 28], 2:...   \n",
       "1  {0: [2, 9, 16, 23, 30], 1: [1, 8, 15, 22, 29],...   \n",
       "2  {0: [3, 10, 17, 24, 31], 1: [2, 9, 16, 23, 30]...   \n",
       "3  {0: [4, 11, 18, 25], 1: [3, 10, 17, 24, 31], 2...   \n",
       "4    {4: [1, 8, 15, 22, 29], 8: [3, 10, 17, 24, 31]}   \n",
       "\n",
       "           valid_years_list      valid_day_list  \n",
       "0  [0, 1, 2, 3, 5, 6, 7, 9]  [1, 8, 15, 22, 29]  \n",
       "1  [0, 1, 2, 3, 5, 6, 7, 9]  [1, 8, 15, 22, 29]  \n",
       "2  [0, 1, 2, 3, 5, 6, 7, 9]  [1, 8, 15, 22, 29]  \n",
       "3  [0, 1, 2, 3, 5, 6, 7, 9]  [1, 8, 15, 22, 29]  \n",
       "4  [4, 8, 4, 4, 4, 4, 4, 4]  [1, 8, 15, 22, 29]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\", converters={#'valid_years_days_dict': eval, \n",
    "                                                 'valid_years_list':eval})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819e6f7-ab45-457b-bf87-61615c359763",
   "metadata": {},
   "source": [
    "**A- training for getting the year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45df77eb-a8e1-42e9-b5ec-dd230aad80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random number generation aka regenerate the same random numbers every time (such as weight and bias initialization )\n",
    "def set_random_seed(seed=7, deterministic=True):\n",
    "    \"\"\"Set random seed, for python, numpy, pytorch\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed to be used.\n",
    "        deterministic (bool): Whether to set the deterministic option for\n",
    "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
    "            to True and `torch.backends.cudnn.benchmark` to False.\n",
    "            Default: True.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False \n",
    "seed=7        \n",
    "set_random_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556798f8-2f85-4c15-a87a-5e8eb28df59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output_year_digit column is just the last number in the output column\n",
    "x_year = df[[\"leap_year_condition\", \"decade\", \"valid_years_list\", \"output_year_digit\"]]\n",
    "y_year = x_year.pop(\"output_year_digit\")\n",
    "v = x_year.pop(\"valid_years_list\")\n",
    "v = pd.DataFrame([i for i in v])\n",
    "# v.head(7), x_year.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6fb9a5e-1376-42ef-a232-4cbb8f4c75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "xtrain_year, xtest_year, ytrain_year, ytest_year, vtrain_year, vtest_year = train_test_split(x_year, y_year, v, test_size=0.19, shuffle=True, random_state=seed, stratify=x_year[\"leap_year_condition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf7a51c-0b87-4b9d-b6ec-7fb2c56d3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectedData(Dataset):\n",
    "    def __init__(self, x, y, v):\n",
    "        self.data = torch.tensor(x.values.astype(np.float32))\n",
    "        self.label = torch.tensor(y.values)\n",
    "        self.valids = torch.tensor(v.values.astype(np.int8))\n",
    "        self.n_smpl = x.shape[0]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx], self.valids[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_smpl    \n",
    "\n",
    "train_set_year = CollectedData(xtrain_year, ytrain_year, vtrain_year)\n",
    "test_set_year = CollectedData(xtest_year, ytest_year, vtest_year)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f0dd21d-1a26-47f1-b539-247bd301243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #replacement for the previous cell\n",
    "# # train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-int(len(dataset)*0.2), int(len(dataset)*0.2)])\n",
    "\n",
    "# train_labels_year = torch.tensor(ytrain_year.values.astype(np.float32)) \n",
    "# test_labels_year = torch.tensor(ytest_year.values.astype(np.float32)) \n",
    "# train_input_year = torch.tensor(xtrain_year.values.astype(np.float32)) \n",
    "# test_input_year = torch.tensor(xtest_year.values.astype(np.float32)) \n",
    "\n",
    "# train_set_year = TensorDataset(train_input_year, train_labels_year)\n",
    "# test_set_year = TensorDataset(test_input_year, test_labels_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a348e6-c679-4bc9-9abe-1772254e1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_year = DataLoader(dataset=train_set_year, shuffle=True, batch_size=batch_size)\n",
    "test_loader_year = DataLoader(dataset=test_set_year, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e0e4d8c-8278-4f9c-a14a-a1b499d63b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class network(nn.Module):\n",
    "    def __init__(self, in_features=2, out_features=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 20)\n",
    "        self.fc2 = nn.Linear(20, 15)\n",
    "        self.fc3 = nn.Linear(15, out_features) \n",
    "        self.initialize_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, inpt):\n",
    "        out = F.leaky_relu(self.fc1(inpt))\n",
    "        out = F.leaky_relu(self.fc2(out))\n",
    "        out = ((self.fc3(out)))#nn.Softmax\n",
    "        return out\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ef6faa-7010-4301-9792-61f137f212df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculating accuracy\n",
    "@torch.no_grad()\n",
    "def calculate_accuracy(model, data_loader=test_loader_year):\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for data, labels, valids in data_loader:\n",
    "        \n",
    "        # transfering data to cuda\n",
    "        data = data.to(device=device)\n",
    "        valids = valids.to(device=device)\n",
    "                \n",
    "        preds = model(data)\n",
    "        num_correct += len([1 for pred, vald in zip(preds.argmax(dim=1), valids) if pred in vald])\n",
    "        num_samples += len(preds)\n",
    "    accuracy = num_correct/num_samples\n",
    "    model.train()\n",
    "    return accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0da7dd2-23a6-4b27-bba5-642421fd2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the network\n",
    "model = network(in_features=2, out_features=10).to(device)\n",
    "lr = 0.001\n",
    "# loss and optimizer initializing\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350619a6-e65d-472e-be51-d6c48ce32129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting learning rate = 0.001 \n",
      " number of epochs = 11 \n",
      " number of batches = 1854 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [1/11], loss=2.1207: 100%|██████████████████████████████████████████████████| 1854/1854 [00:16<00:00, 111.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1 epoch, train_acc = 89.98%, test_acc = 90.11%, time_elapsed = 1.0 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [2/11], loss=2.1698: 100%|███████████████████████████████████████████████████| 1854/1854 [00:20<00:00, 91.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2 epoch, train_acc = 88.28%, test_acc = 88.15%, time_elapsed = 1.2 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [3/11], loss=2.1503: 100%|██████████████████████████████████████████████████| 1854/1854 [00:15<00:00, 116.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3 epoch, train_acc = 85.78%, test_acc = 85.65%, time_elapsed = 1.1 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [4/11], loss=2.0834: 100%|███████████████████████████████████████████████████| 1854/1854 [00:20<00:00, 89.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 4 epoch, train_acc = 85.78%, test_acc = 85.65%, time_elapsed = 1.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [5/11], loss=2.2856: 100%|███████████████████████████████████████████████████| 1854/1854 [00:20<00:00, 89.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 5 epoch, train_acc = 89.98%, test_acc = 90.11%, time_elapsed = 1.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [6/11], loss=2.1194: 100%|███████████████████████████████████████████████████| 1854/1854 [00:18<00:00, 98.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 6 epoch, train_acc = 89.98%, test_acc = 90.11%, time_elapsed = 1.2 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [7/11], loss=2.1112: 100%|███████████████████████████████████████████████████| 1854/1854 [00:18<00:00, 98.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
      "after 7 epoch, train_acc = 89.98%, test_acc = 90.11%, time_elapsed = 1.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [8/11], loss=2.1074: 100%|███████████████████████████████████████████████████| 1854/1854 [00:18<00:00, 99.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 8 epoch, train_acc = 89.98%, test_acc = 90.11%, time_elapsed = 1.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [9/11], loss=2.0833: 100%|███████████████████████████████████████████████████| 1854/1854 [00:20<00:00, 91.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 9 epoch, train_acc = 85.78%, test_acc = 85.65%, time_elapsed = 1.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [10/11], loss=2.1440: 100%|██████████████████████████████████████████████████| 1854/1854 [00:18<00:00, 97.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 epoch, train_acc = 89.98%, test_acc = 90.11%, time_elapsed = 1.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [11/11], loss=2.1110:  74%|█████████████████████████████████████▏            | 1378/1854 [00:15<00:05, 90.86it/s]"
     ]
    }
   ],
   "source": [
    "def train_model(data_loader=train_loader_year):\n",
    "    num_batches = len(data_loader)\n",
    "    num_epochs = 11\n",
    "    print(f\"starting learning rate = {lr} \\n number of epochs = {num_epochs} \\n number of batches = {num_batches} \\n\")\n",
    "    # starting training loop epochs\n",
    "    result_train_acc, result_test_acc = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        progress = tqdm(enumerate(data_loader), total=num_batches, leave=True)\n",
    "        for batch_idx, (data, labels, valids) in progress: \n",
    "\n",
    "            # convert data to device\n",
    "            data = data.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            # valids = valids.to(device=device)\n",
    "\n",
    "            # getting prediction and loss\n",
    "            preds = model(data)\n",
    "            loss = criterion(preds, labels)        \n",
    "\n",
    "            # back propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # optimization step\n",
    "            optimizer.step()\n",
    "\n",
    "            progress.set_description(f\"epoch [{1+epoch}/{num_epochs}], loss={loss.item():0.4f}\")\n",
    "            progress.set_postfix()\n",
    "\n",
    "        train_acc = calculate_accuracy(model, data_loader=train_loader_year)\n",
    "        test_acc = calculate_accuracy(model, data_loader=test_loader_year)\n",
    "        schedular.step(test_acc)\n",
    "        print(f\"after {1+epoch} epoch, train_acc = {(train_acc*100):.2f}%, test_acc = {(test_acc*100):.2f}%, time_elapsed = {((time.time()-start_time)/60):.1f} minuts\")\n",
    "        result_train_acc += [train_acc]\n",
    "        result_test_acc += [test_acc]\n",
    "    return result_train_acc, result_test_acc\n",
    "result_train_acc, result_test_acc = train_model(data_loader=train_loader_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed78cae-20e8-4503-bac3-edadc3471854",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(11)), result_train_acc)\n",
    "plt.title(\"train accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy percentage\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9686c0b-dedd-4242-af92-f81da28fb694",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(11)), result_test_acc)\n",
    "plt.title(\"test accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy percentage\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea31b98-9136-484b-911b-7651bb25c148",
   "metadata": {},
   "source": [
    "**i can easily increase the accuracy of the model by adding additional engineered features like (decade%4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f3974-21dc-48bf-9ba6-9e9bc9211847",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_test = xtest_year\n",
    "dt = r_test.copy(deep=True) \n",
    "r_test = torch.tensor(r_test.values.astype(np.float32)).to(device=device)\n",
    "dt[\"predicted_year_digit\"] = pd.Series(model(r_test).argmax(dim=1).cpu())\n",
    "dt[\"predicted_year\"] = [str(dec+pred) for dec, pred in zip(dt.decade*10, dt.predicted_year_digit)]\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3969fae-2dc5-4563-89cb-b18221f443b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_csv(\"../data/year_predections.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a1e54-6d8c-4026-b424-568ed667f0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e55b6d-ac54-4043-8766-29089fa6bbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
