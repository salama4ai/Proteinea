{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0ec34b8-0bb3-487e-9d11-98ffa61a0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c459028-3062-46c6-8dbc-f2baa9467137",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# fix random number generation aka regenerate the same random numbers every time (such as weight and bias initialization )\n",
    "def set_random_seed(seed=7, deterministic=True):\n",
    "    \"\"\"Set random seed, for python, numpy, pytorch\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed to be used.\n",
    "        deterministic (bool): Whether to set the deterministic option for\n",
    "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
    "            to True and `torch.backends.cudnn.benchmark` to False.\n",
    "            Default: True.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False \n",
    "seed=7        \n",
    "set_random_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f19486a-ed28-4936-86d3-2fd667902629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>month</th>\n",
       "      <th>leap_year_condition</th>\n",
       "      <th>decade</th>\n",
       "      <th>output</th>\n",
       "      <th>output_year_digit</th>\n",
       "      <th>output_year</th>\n",
       "      <th>valid_years_list</th>\n",
       "      <th>valid_day_list</th>\n",
       "      <th>decade4</th>\n",
       "      <th>decade100</th>\n",
       "      <th>decade400</th>\n",
       "      <th>valid_group_days_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1800</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1801</td>\n",
       "      <td>1</td>\n",
       "      <td>1801</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1802</td>\n",
       "      <td>2</td>\n",
       "      <td>1802</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1803</td>\n",
       "      <td>3</td>\n",
       "      <td>1803</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1804</td>\n",
       "      <td>4</td>\n",
       "      <td>1804</td>\n",
       "      <td>[4, 8, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1805</td>\n",
       "      <td>5</td>\n",
       "      <td>1805</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1806</td>\n",
       "      <td>6</td>\n",
       "      <td>1806</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday_name  month  leap_year_condition  decade    output  \\\n",
       "0             2      1                    0     180  1-1-1800   \n",
       "1             3      1                    0     180  1-1-1801   \n",
       "2             4      1                    0     180  1-1-1802   \n",
       "3             5      1                    0     180  1-1-1803   \n",
       "4             6      1                    1     180  1-1-1804   \n",
       "5             1      1                    0     180  1-1-1805   \n",
       "6             2      1                    0     180  1-1-1806   \n",
       "\n",
       "   output_year_digit  output_year          valid_years_list  \\\n",
       "0                  0         1800  [0, 1, 2, 3, 5, 6, 7, 9]   \n",
       "1                  1         1801  [0, 1, 2, 3, 5, 6, 7, 9]   \n",
       "2                  2         1802  [0, 1, 2, 3, 5, 6, 7, 9]   \n",
       "3                  3         1803  [0, 1, 2, 3, 5, 6, 7, 9]   \n",
       "4                  4         1804  [4, 8, 4, 4, 4, 4, 4, 4]   \n",
       "5                  5         1805  [0, 1, 2, 3, 5, 6, 7, 9]   \n",
       "6                  6         1806  [0, 1, 2, 3, 5, 6, 7, 9]   \n",
       "\n",
       "       valid_day_list  decade4  decade100  decade400  valid_group_days_index  \n",
       "0  [1, 8, 15, 22, 29]        0          0          1                       7  \n",
       "1  [1, 8, 15, 22, 29]        0          0          1                       7  \n",
       "2  [1, 8, 15, 22, 29]        0          0          1                       7  \n",
       "3  [1, 8, 15, 22, 29]        0          0          1                       7  \n",
       "4  [1, 8, 15, 22, 29]        0          0          1                       7  \n",
       "5  [1, 8, 15, 22, 29]        0          0          1                       7  \n",
       "6  [1, 8, 15, 22, 29]        0          0          1                       7  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4051fc1-2734-4548-9329-1d083a98f389",
   "metadata": {},
   "source": [
    "- given the columns features we can't by any means diffrentiate between the day 1 or day 8 or 15 or 22 or 28 because they may share the same exact feature columns values and they all still correct, and the model see them all as the same thing, so i make lists for the identical days from the feature columns point of view, and instead of training the model to select certain day, i trained the model to select index of days-list which i named \"groups\", as example if the output of the model is 0 then it equivalent to selecting any day from these days [1, 8, 15, 22], if the output is 1 so it's equivalent to selecting any number from [2, 9, 16, 23] and so on(see groups_dict dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bb579d-7822-4ee1-acca-a13fe49ac40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 8, 15, 22],\n",
       " 1: [2, 9, 16, 23],\n",
       " 2: [3, 10, 17, 24],\n",
       " 3: [4, 11, 18, 25],\n",
       " 4: [5, 12, 19, 26],\n",
       " 5: [6, 13, 20, 27],\n",
       " 6: [7, 14, 21, 28],\n",
       " 7: [1, 8, 15, 22, 29],\n",
       " 8: [2, 9, 16, 23, 30],\n",
       " 9: [3, 10, 17, 24, 31]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all possibole (10) output lists, the output must be one of theses lists\n",
    "groups = [[1, 8, 15, 22], \n",
    "         [2, 9, 16, 23], \n",
    "         [3, 10, 17, 24], \n",
    "         [4, 11, 18, 25], \n",
    "         [5, 12, 19, 26], \n",
    "         [6, 13, 20, 27], \n",
    "         [7, 14, 21, 28],\n",
    "         [1, 8, 15, 22, 29], \n",
    "         [2, 9, 16, 23, 30], \n",
    "         [3, 10, 17, 24, 31]]\n",
    "groups_dict = dict(enumerate(groups))\n",
    "groups_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5166d6-4cd8-4e9d-81f7-946c9d4820de",
   "metadata": {},
   "source": [
    "**B- training for getting the day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a09d7594-25e6-44c6-a479-8eda01194a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>month</th>\n",
       "      <th>output_year</th>\n",
       "      <th>leap_year_condition</th>\n",
       "      <th>valid_group_days_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1802</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1803</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday_name  month  output_year  leap_year_condition  \\\n",
       "0             2      1         1800                    0   \n",
       "1             3      1         1801                    0   \n",
       "2             4      1         1802                    0   \n",
       "3             5      1         1803                    0   \n",
       "4             6      1         1804                    1   \n",
       "\n",
       "   valid_group_days_index  \n",
       "0                       7  \n",
       "1                       7  \n",
       "2                       7  \n",
       "3                       7  \n",
       "4                       7  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"weekday_name\", \"month\", \"output_year\", \"leap_year_condition\", \"valid_group_days_index\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8b36a-7f42-4c84-9717-1d64937a4fd6",
   "metadata": {},
   "source": [
    "**it's obvious that values if the output_year column is very high, and if i train the model this column will dominate the calculations, i need to make standardrization or normalization step, but as i need this value as it, i will do another thing, i will divide this column into two columns, century column and year column to reduce the influence of this column over the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19817ba-e184-40dc-a55a-7fbe72a337af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"century\"] = df.output_year//100\n",
    "# df[\"century_decade\"] = (df.output_year//10)-(df[\"century\"]*10)\n",
    "# df[\"decade_year\"] = df.output_year-(df.output_year//10)*10\n",
    "# df[\"century\"] = df.century-df.century.min()\n",
    "# x_day = df[[\"weekday_name\", \"month\", \"century\", \"century_decade\", \"decade_year\", \"leap_year_condition\", \"valid_group_days_index\"]]\n",
    "# df[\"century\"].unique(), df[\"decade_year\"].unique(), df[\"century_decade\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9340505e-cf4c-4b2b-bd16-c83f5cda78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"century\"] = df.output_year//100\n",
    "# df[\"century_year\"] = df.output_year-df[\"century\"]*100\n",
    "# df[\"century_year\"] = df[\"century_year\"]#/10\n",
    "# df[\"century\"] = df.century-df.century.min()\n",
    "# x_day = df[[\"weekday_name\", \"month\", \"century\", \"century_year\", \"leap_year_condition\", \"valid_group_days_index\"]]\n",
    "# df[\"century\"].unique(), df[\"century_year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9619a2c9-a5d6-4c1c-802b-16ad4dfc3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i used the equation on that site https://artofmemory.com/blog/how-to-calculate-the-day-of-the-week/\n",
    "# to make new engineered feature, to help me increase the accuracy from 28% up to it's current value\n",
    "\n",
    "month_dict = {1:0, 2:3, 3:3, 4:6, 5:1, 6:4, 7:6, 8:2, 9:5, 10:0, 11:3, 12:5}\n",
    "century_dict = {17:4, 18:2, 19:0, 20:6, 21:4, 22:2, 23:0}\n",
    "\n",
    "df[\"century_code\"] = [century_dict[val] for val in (df.output_year//100)]\n",
    "\n",
    "df[\"month_code\"] = [month_dict[val] for val in df.month]\n",
    "\n",
    "df[\"year_code\"] = (df.output_year%100)\n",
    "df[\"year_code\"] = ((df[\"year_code\"]//4)+df[\"year_code\"])%7\n",
    "\n",
    "\n",
    "x_day = df[[\"weekday_name\", \"month_code\", \"century_code\", \"year_code\", \"leap_year_condition\", \"valid_group_days_index\"]]\n",
    "# df[\"century\"].unique(), df[\"year_code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "337f0e28-91d2-465a-8153-2c1cdbeb6b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>month_code</th>\n",
       "      <th>century_code</th>\n",
       "      <th>year_code</th>\n",
       "      <th>leap_year_condition</th>\n",
       "      <th>valid_group_days_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday_name  month_code  century_code  year_code  leap_year_condition  \\\n",
       "0             2           0             2          0                    0   \n",
       "1             3           0             2          1                    0   \n",
       "2             4           0             2          2                    0   \n",
       "3             5           0             2          3                    0   \n",
       "4             6           0             2          5                    1   \n",
       "\n",
       "   valid_group_days_index  \n",
       "0                       7  \n",
       "1                       7  \n",
       "2                       7  \n",
       "3                       7  \n",
       "4                       7  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_day = df[[\"weekday_name\", \"month_code\", \"century_code\", \"year_code\", \"leap_year_condition\", \"valid_group_days_index\"]]\n",
    "x_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b81ec24f-8c99-4736-9009-9470a1f2a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_day = x_day.pop(\"valid_group_days_index\") # from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc1e5c94-b7b7-4809-8cd5-b9f7e12f8556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    22540\n",
      "8    22055\n",
      "3    19248\n",
      "4    19248\n",
      "5    19248\n",
      "6    19248\n",
      "9    14035\n",
      "2     8020\n",
      "1     1604\n",
      "0     1216\n",
      "Name: valid_group_days_index, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(df.valid_group_days_index.value_counts())\n",
    "plt.bar(df.valid_group_days_index.value_counts().index, df.valid_group_days_index.value_counts())\n",
    "plt.xticks(range(10))\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04053cb-4c77-4f69-95cc-16043a2fafb3",
   "metadata": {},
   "source": [
    "**the output column is imbalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cb837f1-a80b-4e7a-bca5-57c92b4f1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "xtrain_day, xtest_day, ytrain_day, ytest_day = train_test_split(x_day, y_day, \n",
    "                                                                test_size=0.19, \n",
    "                                                                shuffle=True, \n",
    "                                                                random_state=seed, \n",
    "                                                                stratify=df.valid_group_days_index)\n",
    "\n",
    "# make oversampling to fix the imbalanced classes\n",
    "ros = RandomOverSampler(random_state=7)\n",
    "x_day_train_sampld, y_day_train_sampld = ros.fit_resample(xtrain_day, ytrain_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3038cc7-d402-42ad-add0-ee54ac269569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytrain_day = 118k,\n",
      "ytest_day = 27k, \n",
      "y_day_train_sampld = 182k\n"
     ]
    }
   ],
   "source": [
    "print(f\"ytrain_day = {len(ytrain_day)//1000}k,\\nytest_day = {len(ytest_day)//1000}k, \\ny_day_train_sampld = {len(x_day_train_sampld)//1000}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4b065c9-defb-4b89-ae78-04eec2314bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    18257\n",
      "9    18257\n",
      "5    18257\n",
      "2    18257\n",
      "4    18257\n",
      "8    18257\n",
      "7    18257\n",
      "3    18257\n",
      "1    18257\n",
      "0    18257\n",
      "Name: valid_group_days_index, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#**after oversampling**\n",
    "pprint(y_day_train_sampld.value_counts())\n",
    "plt.bar(y_day_train_sampld.value_counts().index, y_day_train_sampld.value_counts())\n",
    "plt.xticks(range(10))\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23b2b2c3-33d8-4e16-b680-124fea70d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectedData(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.data = torch.tensor(x.values.astype(np.float32))\n",
    "        self.label = torch.tensor(y.values)\n",
    "        self.n_smpl = x.shape[0]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_smpl    \n",
    "    \n",
    "train_set_day = CollectedData(x_day_train_sampld, y_day_train_sampld)\n",
    "test_set_day = CollectedData(xtest_day, ytest_day)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a6a1a0d-2e8d-4a7a-b0a3-b1f7cac61d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## random_split() isn't suitable here, so that i used train_test_split function\n",
    "# # train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-test_len, int(len(dataset)*0.2)])\n",
    "\n",
    "# train_labels_day = torch.tensor(ytrain_day.values.astype(np.float32)) \n",
    "# test_labels_day = torch.tensor(ytest_day.values.astype(np.float32)) \n",
    "# train_input_day = torch.tensor(xtrain_day.values.astype(np.float32)) \n",
    "# test_input_day = torch.tensor(xtest_day.values.astype(np.float32)) \n",
    "\n",
    "# train_set_day = TensorDataset(train_input_day, train_labels_day)\n",
    "# test_set_day = TensorDataset(test_input_day, test_labels_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4471f16-2365-482e-9381-ec6f16ab3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader_day = DataLoader(dataset=train_set_day, shuffle=True, batch_size=batch_size)\n",
    "test_loader_day = DataLoader(dataset=test_set_day, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0569ef04-1b22-4be1-87b5-2fd7bc29e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    def __init__(self, in_features=5, out_features=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 12)\n",
    "        self.fc2 = nn.Linear(12, 11)\n",
    "        self.fc3 = nn.Linear(11, 21)\n",
    "        self.fc4 = nn.Linear(21, 14)\n",
    "        self.fc5 = nn.Linear(14, 14)\n",
    "        self.fc6 = nn.Linear(14, out_features) \n",
    "        self.initialize_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, inpt):\n",
    "        out = F.relu(self.fc1(inpt))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.leaky_relu(self.fc3(out))\n",
    "        out = F.leaky_relu(self.fc4(out))\n",
    "        # out = F.leaky_relu(self.fc5(out))\n",
    "        out = ((self.fc6(out)))\n",
    "        # out = F.softmax((self.fc6(out)), dim=1)\n",
    "        return out\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "243ae509-c237-4b62-ba60-c1b57ef3bd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculating accuracy\n",
    "@torch.no_grad()\n",
    "def calculate_accuracy(model, data_loader=train_loader_day):\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct, num_samples = 0, 0\n",
    "\n",
    "    for data, labels in data_loader:\n",
    "        \n",
    "        # transfering data to cuda\n",
    "        data = data.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "                \n",
    "        preds = model(data)\n",
    "        num_correct += sum(list(preds.argmax(dim=1)==labels))\n",
    "        num_samples += len(labels)\n",
    "    accuracy = num_correct/num_samples\n",
    "    model.train()\n",
    "    return accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7acd5273-75d7-4238-9144-da877ba3dc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "network(\n",
       "  (fc1): Linear(in_features=5, out_features=12, bias=True)\n",
       "  (fc2): Linear(in_features=12, out_features=11, bias=True)\n",
       "  (fc3): Linear(in_features=11, out_features=21, bias=True)\n",
       "  (fc4): Linear(in_features=21, out_features=14, bias=True)\n",
       "  (fc5): Linear(in_features=14, out_features=14, bias=True)\n",
       "  (fc6): Linear(in_features=14, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing the model\n",
    "model = network(in_features=5, out_features=10).to(device)\n",
    "lr = 0.005\n",
    "# loss and optimizer initializing\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=75, verbose=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261be555-e25f-4e65-83b4-5bc540157bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size = 128 \n",
      " starting learning rate = 0.005 \n",
      " number of epochs = 55    \n",
      " number of batches = 1427 \n",
      " model = network(\n",
      "  (fc1): Linear(in_features=5, out_features=12, bias=True)\n",
      "  (fc2): Linear(in_features=12, out_features=11, bias=True)\n",
      "  (fc3): Linear(in_features=11, out_features=21, bias=True)\n",
      "  (fc4): Linear(in_features=21, out_features=14, bias=True)\n",
      "  (fc5): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (fc6): Linear(in_features=14, out_features=10, bias=True)\n",
      "), \n",
      " criterion=CrossEntropyLoss(), \n",
      " optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [1/55], loss=0.5855: 100%|███████████████████████████████████████████████████| 1427/1427 [00:31<00:00, 44.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1 epoch, train_acc = 83.45%, test_acc = 80.13%,        time_elapsed = 0.6 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [2/55], loss=0.5039: 100%|██████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 109.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2 epoch, train_acc = 87.83%, test_acc = 84.94%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [3/55], loss=0.3410: 100%|███████████████████████████████████████████████████| 1427/1427 [00:14<00:00, 95.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3 epoch, train_acc = 88.76%, test_acc = 86.32%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [4/55], loss=0.4298: 100%|██████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 111.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 4 epoch, train_acc = 86.72%, test_acc = 86.68%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [5/55], loss=0.3944: 100%|██████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 113.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 5 epoch, train_acc = 88.89%, test_acc = 86.05%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [6/55], loss=0.3709: 100%|██████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 112.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 6 epoch, train_acc = 88.38%, test_acc = 86.52%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [7/55], loss=0.3436: 100%|██████████████████████████████████████████████████| 1427/1427 [00:11<00:00, 127.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 7 epoch, train_acc = 89.02%, test_acc = 86.38%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [8/55], loss=0.2442: 100%|██████████████████████████████████████████████████| 1427/1427 [00:11<00:00, 123.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 8 epoch, train_acc = 88.55%, test_acc = 86.60%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [9/55], loss=0.3147: 100%|██████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 103.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 9 epoch, train_acc = 88.05%, test_acc = 86.83%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [10/55], loss=0.1904: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 108.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 epoch, train_acc = 85.81%, test_acc = 82.41%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [11/55], loss=0.2550: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 108.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 11 epoch, train_acc = 87.60%, test_acc = 85.43%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [12/55], loss=0.1938: 100%|█████████████████████████████████████████████████| 1427/1427 [00:11<00:00, 120.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 12 epoch, train_acc = 88.38%, test_acc = 86.61%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [13/55], loss=0.2125: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 118.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 13 epoch, train_acc = 88.62%, test_acc = 87.06%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [14/55], loss=0.1217: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 106.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 14 epoch, train_acc = 89.19%, test_acc = 86.67%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [15/55], loss=0.1860: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 113.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 15 epoch, train_acc = 88.70%, test_acc = 86.90%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [16/55], loss=0.4146: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 112.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 16 epoch, train_acc = 88.19%, test_acc = 86.85%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [17/55], loss=0.3368: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 106.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 17 epoch, train_acc = 89.01%, test_acc = 87.14%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [18/55], loss=0.1532: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 109.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 18 epoch, train_acc = 89.11%, test_acc = 86.60%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [19/55], loss=0.2757: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 106.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 19 epoch, train_acc = 88.88%, test_acc = 86.54%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [20/55], loss=0.3709: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 110.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 20 epoch, train_acc = 89.11%, test_acc = 86.95%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [21/55], loss=0.3101: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 107.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 21 epoch, train_acc = 89.42%, test_acc = 86.78%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [22/55], loss=0.4331: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 108.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 22 epoch, train_acc = 89.07%, test_acc = 87.18%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [23/55], loss=0.0830: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 108.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 23 epoch, train_acc = 87.94%, test_acc = 85.59%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [24/55], loss=0.3253: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 107.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 24 epoch, train_acc = 88.39%, test_acc = 86.76%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [25/55], loss=0.2332: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 108.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 25 epoch, train_acc = 89.24%, test_acc = 87.04%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [26/55], loss=0.2111: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 110.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 26 epoch, train_acc = 88.69%, test_acc = 86.71%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [27/55], loss=0.1176: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 110.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 27 epoch, train_acc = 89.27%, test_acc = 86.91%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [28/55], loss=0.2087: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 109.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 28 epoch, train_acc = 89.39%, test_acc = 86.80%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [29/55], loss=0.2639: 100%|█████████████████████████████████████████████████| 1427/1427 [00:13<00:00, 103.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 29 epoch, train_acc = 89.25%, test_acc = 86.95%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [30/55], loss=0.1351: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 113.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 30 epoch, train_acc = 88.83%, test_acc = 87.24%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [31/55], loss=0.1584: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 113.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 31 epoch, train_acc = 89.27%, test_acc = 86.91%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [32/55], loss=0.2274: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 110.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 32 epoch, train_acc = 88.13%, test_acc = 87.63%,        time_elapsed = 0.4 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [33/55], loss=0.1794: 100%|█████████████████████████████████████████████████| 1427/1427 [00:12<00:00, 114.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 33 epoch, train_acc = 89.03%, test_acc = 86.77%,        time_elapsed = 0.3 minuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch [34/55], loss=0.3485:  49%|████████████████████████▋                         | 705/1427 [00:06<00:06, 117.58it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 55\n",
    "def train_model(num_epochs, data_loader=train_loader_day):\n",
    "    num_batches = len(data_loader)\n",
    "    print(f\"\"\"batch_size = {batch_size} \\n starting learning rate = {lr} \\n number of epochs = {num_epochs}\\\n",
    "    \\n number of batches = {num_batches} \\n model = {model}, \\n criterion={criterion}, \\n optimizer={optimizer}\"\"\")\n",
    "   \n",
    "    # starting training loop epochs\n",
    "    result_train_acc, result_test_acc = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        progress = tqdm(enumerate(data_loader), total=num_batches, leave=True)\n",
    "        for batch_idx, (data, labels) in progress: \n",
    "\n",
    "            # convert data to device\n",
    "            data = data.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            # getting prediction and loss\n",
    "            preds = model(data)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            # back propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # optimization step\n",
    "            optimizer.step()\n",
    "\n",
    "            progress.set_description(f\"epoch [{1+epoch}/{num_epochs}], loss={loss.item():0.4f}\")\n",
    "            progress.set_postfix()\n",
    "\n",
    "        train_acc = calculate_accuracy(model, data_loader=train_loader_day)\n",
    "        test_acc = calculate_accuracy(model, data_loader=test_loader_day)\n",
    "        schedular.step(test_acc)\n",
    "        print(f\"after {1+epoch} epoch, train_accuracy = {(train_acc*100):.2f}%, test_accuracy = {(test_acc*100):.2f}%,\\\n",
    "        time_elapsed = {((time.time()-start_time)/60):.1f} minuts\")\n",
    "        result_train_acc += [train_acc]\n",
    "        result_test_acc += [test_acc]\n",
    "    return result_train_acc, result_test_acc\n",
    "result_train_acc, result_test_acc = train_model(num_epochs, data_loader=train_loader_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026b82e8-ae5e-41a9-bc13-ad94585209b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"maximun training accuracy={(max(result_train_acc)*100):.2f}%\\nmaximun test accuracy={(max(result_test_acc))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291886a6-0c26-4ac8-819e-554b193fd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_line_val = np.array([val.cpu() for val in result_train_acc]) # just replace val with val.cpu() if output is cuda\n",
    "test_line_val = np.array([val.cpu() for val in result_test_acc]) # just replace val with val.cpu() if output is cuda\n",
    "\n",
    "train_line, = plt.plot((range(len(train_line_val))), train_line_val, label=\"train accuracy\", marker=\"*\", linewidth=5)\n",
    "test_line, = plt.plot((range(len(test_line_val))), test_line_val, label=\"test accuracy\", marker=\"o\", linewidth=2.5)\n",
    "plt.legend(loc=\"best\", handles=[train_line, test_line])\n",
    "plt.title(\"train & test accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy percentage\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7e710-d5de-4a5a-913a-af6d8f807df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xtest_day\n",
    "dt = d_test.copy(deep=True)\n",
    "d_test = torch.tensor(d_test.values.astype(np.float32))\n",
    "preds = model(d_test.to(device=device)).argmax(dim=1).cpu()\n",
    "dt[\"predicted_days_group_index\"] = preds\n",
    "dt[\"correct_output\"] = ytest_day\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e045d-a7b7-47bf-b1e0-8936128ec27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_tensor = torch.tensor((xtest_daydf[[\"weekday_name\", \"month_code\", \"century_code\", \"year_code\", \"leap_year_condition\"]].values.astype(np.float32)))\n",
    "preds = model(days_tensor.to(device=device)).argmax(dim=1).cpu()\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66548e8b-6d86-41ea-9324-c68afb7d58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../data/day_model_saved\")\n",
    "model = torch.load(\"../data/day_model_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993839c3-cabd-4ba6-9142-9a8e374e471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_csv(\"../data/day_predections.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b81e2b-3a15-460f-8f34-72ff7362e3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
