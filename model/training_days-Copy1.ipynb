{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ec34b8-0bb3-487e-9d11-98ffa61a0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f19486a-ed28-4936-86d3-2fd667902629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>month</th>\n",
       "      <th>leap_year_condition</th>\n",
       "      <th>decade</th>\n",
       "      <th>output</th>\n",
       "      <th>output_year_digit</th>\n",
       "      <th>output_year</th>\n",
       "      <th>output_day</th>\n",
       "      <th>valid_years_days_dict</th>\n",
       "      <th>valid_years_list</th>\n",
       "      <th>valid_day_list</th>\n",
       "      <th>decade4</th>\n",
       "      <th>decade100</th>\n",
       "      <th>decade400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1800</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [1, 8, 15, 22, 29], 1: [7, 14, 21, 28], 2:...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1801</td>\n",
       "      <td>1</td>\n",
       "      <td>1801</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [2, 9, 16, 23, 30], 1: [1, 8, 15, 22, 29],...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1802</td>\n",
       "      <td>2</td>\n",
       "      <td>1802</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [3, 10, 17, 24, 31], 1: [2, 9, 16, 23, 30]...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1803</td>\n",
       "      <td>3</td>\n",
       "      <td>1803</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: [4, 11, 18, 25], 1: [3, 10, 17, 24, 31], 2...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 9]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>1-1-1804</td>\n",
       "      <td>4</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "      <td>{4: [1, 8, 15, 22, 29], 8: [3, 10, 17, 24, 31]}</td>\n",
       "      <td>[4, 8, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[1, 8, 15, 22, 29]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday_name  month  leap_year_condition  decade    output  \\\n",
       "0             2      1                    0     180  1-1-1800   \n",
       "1             3      1                    0     180  1-1-1801   \n",
       "2             4      1                    0     180  1-1-1802   \n",
       "3             5      1                    0     180  1-1-1803   \n",
       "4             6      1                    1     180  1-1-1804   \n",
       "\n",
       "   output_year_digit  output_year  output_day  \\\n",
       "0                  0         1800           1   \n",
       "1                  1         1801           1   \n",
       "2                  2         1802           1   \n",
       "3                  3         1803           1   \n",
       "4                  4         1804           1   \n",
       "\n",
       "                               valid_years_days_dict  \\\n",
       "0  {0: [1, 8, 15, 22, 29], 1: [7, 14, 21, 28], 2:...   \n",
       "1  {0: [2, 9, 16, 23, 30], 1: [1, 8, 15, 22, 29],...   \n",
       "2  {0: [3, 10, 17, 24, 31], 1: [2, 9, 16, 23, 30]...   \n",
       "3  {0: [4, 11, 18, 25], 1: [3, 10, 17, 24, 31], 2...   \n",
       "4    {4: [1, 8, 15, 22, 29], 8: [3, 10, 17, 24, 31]}   \n",
       "\n",
       "           valid_years_list      valid_day_list  decade4  decade100  decade400  \n",
       "0  [0, 1, 2, 3, 5, 6, 7, 9]  [1, 8, 15, 22, 29]        0          0          1  \n",
       "1  [0, 1, 2, 3, 5, 6, 7, 9]  [1, 8, 15, 22, 29]        0          0          1  \n",
       "2  [0, 1, 2, 3, 5, 6, 7, 9]  [1, 8, 15, 22, 29]        0          0          1  \n",
       "3  [0, 1, 2, 3, 5, 6, 7, 9]  [1, 8, 15, 22, 29]        0          0          1  \n",
       "4  [4, 8, 4, 4, 4, 4, 4, 4]  [1, 8, 15, 22, 29]        0          0          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\", converters={#'valid_years_days_dict': eval, \n",
    "                                                 'valid_day_list':eval})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a09d7594-25e6-44c6-a479-8eda01194a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_day = df[[\"weekday_name\", \"month\", \"output_year\", \"output_day\", \"valid_day_list\"]]\n",
    "y_day = x_day.pop(\"output_day\")\n",
    "v = x_day.pop(\"valid_day_list\")\n",
    "v = pd.DataFrame([i for i in v])\n",
    "# v.head(), x_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5166d6-4cd8-4e9d-81f7-946c9d4820de",
   "metadata": {},
   "source": [
    "**B- training for getting the day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c459028-3062-46c6-8dbc-f2baa9467137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random number generation aka regenerate the same random numbers every time (such as weight and bias initialization )\n",
    "def set_random_seed(seed=7, deterministic=True):\n",
    "    \"\"\"Set random seed, for python, numpy, pytorch\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed to be used.\n",
    "        deterministic (bool): Whether to set the deterministic option for\n",
    "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
    "            to True and `torch.backends.cudnn.benchmark` to False.\n",
    "            Default: True.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False \n",
    "seed=7        \n",
    "set_random_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb837f1-a80b-4e7a-bca5-57c92b4f1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "xtrain_day, xtest_day, ytrain_day, ytest_day, vtrain_day, vtest_day = train_test_split(x_day, y_day, v, test_size=0.19, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b2b2c3-33d8-4e16-b680-124fea70d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectedData(Dataset):\n",
    "    def __init__(self, x, y, v):\n",
    "        self.data = torch.tensor(x.values.astype(np.float32))\n",
    "        self.label = torch.tensor(y.values)\n",
    "        self.valids = torch.tensor(v.values.astype(np.int8))\n",
    "        self.n_smpl = x.shape[0]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx], self.valids[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_smpl    \n",
    "    \n",
    "train_set_day = CollectedData(xtrain_day, ytrain_day, vtrain_day)\n",
    "test_set_day = CollectedData(xtest_day, ytest_day, vtest_day)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6a1a0d-2e8d-4a7a-b0a3-b1f7cac61d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this isn't suitable here, so that i used train_test_split function\n",
    "# # train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-test_len, int(len(dataset)*0.2)])\n",
    "\n",
    "# train_labels_day = torch.tensor(ytrain_day.values.astype(np.float32)) \n",
    "# test_labels_day = torch.tensor(ytest_day.values.astype(np.float32)) \n",
    "# train_input_day = torch.tensor(xtrain_day.values.astype(np.float32)) \n",
    "# test_input_day = torch.tensor(xtest_day.values.astype(np.float32)) \n",
    "\n",
    "# train_set_day = TensorDataset(train_input_day, train_labels_day)\n",
    "# test_set_day = TensorDataset(test_input_day, test_labels_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4471f16-2365-482e-9381-ec6f16ab3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_day = DataLoader(dataset=train_set_day, shuffle=True, batch_size=batch_size)\n",
    "# test_loader_day = DataLoader(dataset=test_set_day, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0569ef04-1b22-4be1-87b5-2fd7bc29e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class network(nn.Module):\n",
    "    def __init__(self, in_features=3, out_features=31):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 31)\n",
    "        self.fc2 = nn.Linear(31, 31)\n",
    "        self.fc3 = nn.Linear(31, 31)\n",
    "        self.fc4 = nn.Linear(31, out_features) \n",
    "        self.initialize_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, inpt):\n",
    "        out = F.leaky_relu(self.fc1(inpt))\n",
    "        out = F.leaky_relu(self.fc2(out))\n",
    "        out = F.leaky_relu(self.fc3(out))\n",
    "        out = ((self.fc4(out)))#nn.Softmax\n",
    "        return out\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "243ae509-c237-4b62-ba60-c1b57ef3bd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculating accuracy\n",
    "@torch.no_grad()\n",
    "def calculate_accuracy(model, data_loader=train_loader_day):\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for data, labels, valids in data_loader:\n",
    "        \n",
    "        # transfering data to cuda\n",
    "        data = data.to(device=device)\n",
    "        valids = valids.to(device=device)\n",
    "                \n",
    "        preds = model(data)\n",
    "        num_correct += len([1 for pred, vald in zip(preds.argmax(dim=1), valids) if pred in vald])\n",
    "        num_samples += len(preds)\n",
    "    accuracy = num_correct/num_samples\n",
    "    model.train()\n",
    "    return accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7acd5273-75d7-4238-9144-da877ba3dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the network\n",
    "model = network(in_features=3, out_features=31).to(device)\n",
    "lr = 0.01\n",
    "# loss and optimizer initializing\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.00001, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "261be555-e25f-4e65-83b4-5bc540157bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting learning rate = 0.01 \n",
      " number of epochs = 31 \n",
      " number of batches = 1854 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1854 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5752/2413804927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mresult_test_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult_train_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_test_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mresult_train_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_test_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loader_day\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5752/2413804927.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(num_epochs, data_loader)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m# getting prediction and loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5752/809204581.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inpt)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "num_epochs = 31\n",
    "def train_model(num_epochs, data_loader=train_loader_day):\n",
    "    num_batches = len(data_loader)\n",
    "    print(f\"starting learning rate = {lr} \\n number of epochs = {num_epochs} \\n number of batches = {num_batches} \\n\")\n",
    "    # starting training loop epochs\n",
    "    result_train_acc, result_test_acc = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        progress = tqdm(enumerate(data_loader), total=num_batches, leave=True)\n",
    "        for batch_idx, (data, labels, valids) in progress: \n",
    "\n",
    "            # convert data to device\n",
    "            data = data.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            valids = valids.to(device=device)\n",
    "\n",
    "            # getting prediction and loss\n",
    "            preds = model(data)\n",
    "            loss = criterion(preds, labels)        \n",
    "\n",
    "            # back propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # optimization step\n",
    "            optimizer.step()\n",
    "\n",
    "            progress.set_description(f\"epoch [{1+epoch}/{num_epochs}], loss={loss.item():0.4f}\")\n",
    "            progress.set_postfix()\n",
    "\n",
    "        train_acc = calculate_accuracy(model, data_loader=train_loader_day)\n",
    "        test_acc = calculate_accuracy(model, data_loader=test_loader_day)\n",
    "        schedular.step(test_acc)\n",
    "        print(f\"after {1+epoch} epoch, train_acc = {(train_acc*100):.2f}%, test_acc = {(test_acc*100):.2f}%, time_elapsed = {((time.time()-start_time)/60):.1f} minuts\")\n",
    "        result_train_acc += [train_acc]\n",
    "        result_test_acc += [test_acc]\n",
    "    return result_train_acc, result_test_acc\n",
    "result_train_acc, result_test_acc = train_model(num_epochs, data_loader=train_loader_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291886a6-0c26-4ac8-819e-554b193fd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(num_epochs)), result_train_acc)\n",
    "plt.title(\"train accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e311c1-4e2c-49f3-b484-7c28e6f2aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(num_epochs)), result_test_acc)\n",
    "plt.title(\"test accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdf7e710-d5de-4a5a-913a-af6d8f807df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>month</th>\n",
       "      <th>output_year</th>\n",
       "      <th>predicted_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100361</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1911</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99263</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2057</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127052</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2136</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62177</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1822</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9395</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1972</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69251</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2079</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33138</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2056</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136452</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1815</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53075</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1943</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27828 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        weekday_name  month  output_year  predicted_day\n",
       "100361             1     11         1911              2\n",
       "99263              6      8         2016              2\n",
       "6673               2      5         2057              2\n",
       "127052             6      5         2136              2\n",
       "62177              4     12         1822              2\n",
       "...              ...    ...          ...            ...\n",
       "9395               5     12         1972              2\n",
       "69251              0      5         2079              2\n",
       "33138              1     11         2056              2\n",
       "136452             3      6         1815              2\n",
       "53075              1      1         1943              2\n",
       "\n",
       "[27828 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_test = xtest_day\n",
    "dt = d_test.copy(deep=True)\n",
    "d_test = torch.tensor(d_test.values.astype(np.float32))\n",
    "preds = model(d_test.to(device=device)).argmax(dim=1).cpu()\n",
    "dt[\"predicted_day\"] = preds\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b77e045d-a7b7-47bf-b1e0-8936128ec27f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (146462x2 and 3x31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13256/2253757960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0myear_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"leap_year_condition\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"decade\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"predicted_year_digit\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"decade\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecade\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13256/809204581.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inpt)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (146462x2 and 3x31)"
     ]
    }
   ],
   "source": [
    "days_tensor = torch.tensor(d_test[[\"weekday_name\", \"month\", \"output_year\"]].values.astype(np.float32))\n",
    "preds = model(days_tensor.to(device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66548e8b-6d86-41ea-9324-c68afb7d58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../data/day_model_saved\")\n",
    "model = torch.load(\"../data/day_model_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "993839c3-cabd-4ba6-9142-9a8e374e471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_csv(\"../data/day_predections.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258cb52e-e1d2-4b7b-a526-f17fead2fa68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14181f-fb4a-49d4-a2a4-e508396b8413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
